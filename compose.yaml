services:
  app:
    image: nikolaysus/postic-ml:ollama-required-python-3.12.10-all-rest
    container_name: app_service
    environment:
      - OLLAMA_HOST=http://ollama:11434
      - HOST=0.0.0.0
      - PORT=8000
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - GOOGLE_GCS_KEY=oops
      - GOOGLE_GCS_ID=oops
    ports:
      - "8000:8000"
    depends_on:
      - ollama
      - qdrant
      - redis
    restart: unless-stopped

  ollama:
    image: ollama/ollama:0.6.8
    entrypoint:
      [
        "/bin/bash",
        "-c",
        "ollama serve & sleep 5 && ollama pull gemma3:4b && ollama pull bge-m3:567m && wait",
      ]
    container_name: ollama
    runtime: nvidia
    ports:
      - "11434:11434"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              count: all
    volumes:
      - ollama:/root/.ollama
      - models:/models
    restart: unless-stopped

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant_for_publication
    ports:
      - "6333:6333"
      - "6334:6334"
    expose:
      - "6333"
      - "6334"
    restart: unless-stopped

  redis:
    image: redis:latest
    container_name: redis_cache
    ports:
      - "6379:6379"
    expose:
      - "6379"
    restart: unless-stopped

volumes:
  ollama:
  models:
